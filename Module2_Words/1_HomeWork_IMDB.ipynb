{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToKpETQw6QNO"
      },
      "source": [
        "Загружаем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4b4gaQNBJjQ",
        "outputId": "b15f1d31-fb7e-4828-ab64-fff22468e2c8"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "#! pip install pymorphy2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import *\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFLw2o-zBJjS"
      },
      "source": [
        "## Загружаем данные\n",
        "\n",
        "Данные записаны в формате `json`. Для его чтения воспользуемся библиотекой `json` и методом `open`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdpKqJiPncFE",
        "outputId": "dd01b377-c2ad-41b8-d0fa-3fa669ddbc26"
      },
      "outputs": [],
      "source": [
        "#!unzip 'IMDB Dataset.csv.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oF-J7rimBJjV"
      },
      "outputs": [],
      "source": [
        "# Загружаем данные\n",
        "try:\n",
        "    data = pd.read_csv('IMDB Dataset.csv', encoding= \"utf-8\")\n",
        "except:\n",
        "    data = pd.read_csv('IMDB Dataset.csv', encoding= \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5  Probably my all-time favorite movie, a story o...  positive\n",
              "6  I sure would like to see a resurrection of a u...  positive\n",
              "7  This show was an amazing, fresh & innovative i...  negative\n",
              "8  Encouraged by the positive comments about this...  negative\n",
              "9  If you like original gut wrenching laughter yo...  positive"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNZlUXTn0Oos"
      },
      "source": [
        "Будем решать задачу классификации на 3 класса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "проверяем наличие NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['review'].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Проверяем дубли"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[49582 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "data = data.drop_duplicates(subset=['review'], keep='first')\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BBZhvydBz1E",
        "outputId": "9be11412-9c6e-4495-865b-56a61166201f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       object\n",
              "sentiment    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print(set([x[\"rating\"] for x in data]))\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.astype({\"sentiment\": \"string\"})\n",
        "data = data.astype({\"review\": \"string\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       string\n",
              "sentiment    string\n",
              "dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "679"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col_bytes_len = data['review'].max()\n",
        "len(col_bytes_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество отзывов для каждого рейтинга:\n",
            "sentiment\n",
            "negative    24698\n",
            "positive    24884\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "rating_counts = data.groupby('sentiment')\n",
        "print(\"Количество отзывов для каждого рейтинга:\")\n",
        "print(rating_counts.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNlcOsYi0rae"
      },
      "source": [
        "# Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0YQ8azssBJjY"
      },
      "outputs": [],
      "source": [
        "import nltk   # Natural Language Toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6aMrY2BJjZ",
        "outputId": "defd8a2c-17ba-4eb8-eaa3-ff863653e2f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/kbudakovskiy/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# загружаем список стоп-слов для русского\n",
        "nltk.download('stopwords')\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# примеры стоп-слов\n",
        "print(len(stop_words))\n",
        "print(stop_words[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaOE5jnH6QNg"
      },
      "source": [
        "Инициализируем `WordPunctTokenizer`, с помощью которого затем разобьем текст на слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_tokenizer = nltk.WordPunctTokenizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg947Mrc6QNg"
      },
      "source": [
        "Запишем предобработку текста в виде функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nmCdblcaBJjd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "regex = re.compile(r'[A-z]+')\n",
        "\n",
        "def words_only(text, regex=regex):\n",
        "    try:\n",
        "        return \" \".join(regex.findall(text)).lower()\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "# расширим список стоп-слов, словами, которые являеются стоп-словами в данной задаче\n",
        "add_stop_words = ['br']\n",
        "all_stop_words = stop_words + add_stop_words\n",
        "\n",
        "\n",
        "def process_data(data):\n",
        "    texts = []\n",
        "    targets = []\n",
        "\n",
        "    # поочередно проходим по всем новостям в списке\n",
        "    for item in tqdm(data):\n",
        "\n",
        "        text_lower = words_only(item) # оставим только слова\n",
        "        tokens     = word_tokenizer.tokenize(text_lower) #разбиваем текст на слова\n",
        "\n",
        "        # удаляем пунктуацию и стоп-слова\n",
        "        tokens = [word for word in tokens if (word not in all_stop_words and not word.isnumeric())]\n",
        "\n",
        "        texts.append(tokens) # добавляем в предобработанный список\n",
        "\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OPuPlD7BJjd",
        "outputId": "e7325c74-4d6a-4d28-aeff-06620fae5d40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49582/49582 [00:10<00:00, 4897.62it/s]\n"
          ]
        }
      ],
      "source": [
        "# запускаем нашу предобработку\n",
        "y = data[\"sentiment\"].tolist()\n",
        "texts = process_data(data[\"review\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUkC7UlgBJje",
        "outputId": "695cbe5a-57aa-4bb4-a106-74c06f131fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label:  negative\n",
            "Tokens:  ['plot', 'death', 'little', 'children', 'hopper']\n"
          ]
        }
      ],
      "source": [
        "# example\n",
        "i = 36\n",
        "print(\"Label: \", y[i])\n",
        "print(\"Tokens: \", texts[i][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y4dg8BwbBJjg"
      },
      "outputs": [],
      "source": [
        "# загружаем библиотеку для лемматизации\n",
        "import pymorphy2 # Морфологический анализатор\n",
        "\n",
        "# инициализируем лемматизатор :)\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLDccTjU6QNi"
      },
      "source": [
        "Посмотрим на примерах, как работает лемматизация."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaPT-b1fBJjh",
        "outputId": "87a5fa3d-4879-4a8a-f5ec-a3a6823cd612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Исходное слово: wonderful\tЛемматизированное: wonderful\n",
            "Исходное слово: little\tЛемматизированное: little\n",
            "Исходное слово: production\tЛемматизированное: production\n",
            "Исходное слово: filming\tЛемматизированное: filming\n",
            "Исходное слово: technique\tЛемматизированное: technique\n",
            "Исходное слово: unassuming\tЛемматизированное: unassuming\n",
            "Исходное слово: old\tЛемматизированное: old\n",
            "Исходное слово: time\tЛемматизированное: time\n",
            "Исходное слово: bbc\tЛемматизированное: bbc\n",
            "Исходное слово: fashion\tЛемматизированное: fashion\n"
          ]
        }
      ],
      "source": [
        "i = 1\n",
        "for aword in texts[i][:10]:\n",
        "    aword_norm = morph.parse(aword)[0].normal_form\n",
        "    print(\"Исходное слово: %s\\tЛемматизированное: %s\" % (aword, aword_norm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3UFLXWJVoHQV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 24586/49582 [00:26<00:26, 945.53it/s] "
          ]
        }
      ],
      "source": [
        "# применяем лемматизацию ко всем текстам\n",
        "for i in tqdm(range(len(texts))):           # tqdm_notebook создает шкалу прогресса :)\n",
        "    text_lemmatized = [morph.parse(x)[0].normal_form for x in texts[i]] # применяем лемматизацию для каждого слова в тексте\n",
        "    texts[i] = ' '.join(text_lemmatized)                # объединяем все слова в одну строку через пробел"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-7Svmby6QNl"
      },
      "source": [
        "Посмотрим на пример."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eWDYSn6BJji",
        "outputId": "d03dc3e4-9fae-4fa5-ea72-3bba783a09cf"
      },
      "outputs": [],
      "source": [
        "# посмотрим на пример\n",
        "i = 1\n",
        "print(\"Label: \",   y[i])\n",
        "print(\"Text: \\n\",  texts[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLPpW3iR4Xn2"
      },
      "source": [
        "# Моделирование & Векторные представления"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq1t2c-1BJjj"
      },
      "source": [
        "## Разбиваем на train&test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eWUtNl36QNl"
      },
      "source": [
        "Лейблы у нас также закодированы словами. Для корректной работы алгорима конвертируем их в числа (`'negative', 'neutral', 'positive'`):\n",
        "\n",
        "    negative = -1\n",
        "    neutral  = 0\n",
        "    positive = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrhjwhR56QNl"
      },
      "outputs": [],
      "source": [
        "# Функция для кодирования лейблов\n",
        "def label2num(y):\n",
        "    if y == 'positive':\n",
        "        return 1\n",
        "    if y == 'negative':\n",
        "        return -1\n",
        "\n",
        "encoded_y = [label2num(yy) for yy in y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(encoded_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsEcoPTo6QNm"
      },
      "source": [
        "**Эффективность алгоритма некорректно оценивать на обучающих данных!** Это все равно что на контрольной ученику давать задачи, разобранные в классе.\n",
        "\n",
        "Поэтому мы отложим часть данных для тестирования и оценки качества алгоритма. Для этого воспользуемся функцией `train_test_split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGSTMZ-5BJjk"
      },
      "outputs": [],
      "source": [
        "#train test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, test_texts, train_y, test_y = train_test_split(texts, encoded_y, test_size=0.2, random_state=42, stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Инициализируем векторайзер\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features = 100)\n",
        "vectorizer.fit(train_texts)\n",
        "\n",
        "# Топ-10 слов\n",
        "vectorizer.get_feature_names_out()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Обучаем vectorizer на train-данных и сразу преобразем их в вектора с помощью метода fit_transform\n",
        "train_X = vectorizer.transform(train_texts)\n",
        "train_X.todense()[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_X  = vectorizer.transform(test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import алгоритма из библиотеки\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# инициализируем модель\n",
        "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
        "\n",
        "# обучаем ее на тренировочных данных\n",
        "clf = clf.fit(train_X, train_y)\n",
        "\n",
        "# делаем предсказание для тестовых данных\n",
        "pred = clf.predict(test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86r2qDjV6QNt"
      },
      "source": [
        "### Оценка качества\n",
        "\n",
        "Качество классификатора будем оценивать по метрикам accuracy и f1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhXYLfIl6QNu",
        "outputId": "4ec76c90-d89b-4ff3-e4ab-7a6c93a90708"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', accuracy_score(test_y, pred))\n",
        "print('F1: ', f1_score(test_y, pred, average = 'macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSo4OBph6QNu"
      },
      "source": [
        "# Посмотрим на несколько примеров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjadFZAy6QNu",
        "outputId": "a1f04824-474d-49a9-c57f-8ff716bc962a"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    print('Истинный лейбл:',decoded_test_y[i])\n",
        "    print('Предсказанный лейбл:',decoded_pred[i])\n",
        "    print('Текст новости: ', train_texts[i][:500]+'...')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqpUSs2f6QNv",
        "outputId": "6f2a48c3-893d-4f67-b34f-c91c18b0fc7c"
      },
      "outputs": [],
      "source": [
        "#вычисляем tf-idf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Fit TF-IDF on train texts\n",
        "vectorizer = TfidfVectorizer(max_features = 5000, norm = None) # возмем топ 200 слов\n",
        "vectorizer.fit(train_texts)\n",
        "\n",
        "# Топ-10 слов\n",
        "vectorizer.get_feature_names_out()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEWdcqIDOQOh"
      },
      "outputs": [],
      "source": [
        "# Обучаем TF-IDF на train, а затем применяем к train и test\n",
        "train_X = vectorizer.fit_transform(train_texts)\n",
        "test_X  = vectorizer.transform(test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpLQOh1-OQOh",
        "outputId": "e9c2ef8b-100e-4578-cba6-0f09c645d7fc",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Пример\n",
        "train_X.todense()[:2] # посмотрим на первые 2 строки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOW0ccLuOQOh"
      },
      "source": [
        "## Обучаем классификатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA5nashGOQOi"
      },
      "outputs": [],
      "source": [
        "#import алгоритма из библиотеки\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# инициализируем модель\n",
        "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
        "\n",
        "# обучаем ее на тренировочных данных\n",
        "clf = clf.fit(train_X, train_y)\n",
        "\n",
        "# делаем предсказание для тестовых данных\n",
        "pred = clf.predict(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvlfKE_zOQOi",
        "outputId": "9df95e61-b08c-4350-abce-23b244b8bee9"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', accuracy_score(test_y, pred))\n",
        "print('F1: ', f1_score(test_y, pred, average = 'macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTBnYkTMOQOi"
      },
      "source": [
        "## Посмотрим на несколько примеров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns2V-GcJOQOi",
        "outputId": "d5aa5a0c-a9ea-4b29-c7b3-0fd33cc8245b"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    print('Истинный лейбл:',decoded_test_y[i])\n",
        "    print('Предсказанный лейбл:',decoded_pred[i])\n",
        "    print('Текст новости: ', train_texts[i][:500]+'...')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "        'n_estimators': range(470, 490, 1),\n",
        "        'max_depth': range(5, 15, 5)\n",
        "}\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='f1', verbose=1)\n",
        "grid_search.fit(train_X, train_y)\n",
        "\n",
        "print(\"Best CV score: {:.3f}, best CV n_estimators: {}\".format(\n",
        "    grid_search.best_score_, grid_search.best_estimator_.n_estimators)\n",
        ") \n",
        "\n",
        "\n",
        "test_predictions = grid_search.best_estimator_.predict(test_X)\n",
        "print(\"Resulting test score: {:.3f}\".format(f1_score(test_predictions, test_y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_weights = train_X.toarray()\n",
        "tfidf_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Из чата GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Получение tf-idf весов\n",
        "tfidf_weights = train_X.toarray()\n",
        "\n",
        "# Векторизация текста с весами tf-idf и word2vec\n",
        "def vectorize_with_tfidf_and_word2vec(text, tfidf_weights, word2vec_model):\n",
        "    word_vectors = []\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        if word in word2vec_model:\n",
        "            # Получение вектора word2vec для слова\n",
        "            w2v_vector = word2vec_model[word]\n",
        "            # Получение tf-idf веса для слова\n",
        "            tfidf_weight = tfidf_weights[words.index(word)]\n",
        "            # Умножение вектора word2vec на tf-idf вес\n",
        "            weighted_w2v_vector = w2v_vector * tfidf_weight\n",
        "            word_vectors.append(weighted_w2v_vector)\n",
        "    \n",
        "    if word_vectors:\n",
        "        # Усреднение векторов слов для получения вектора предложения\n",
        "        sentence_vector = np.mean(word_vectors, axis=0)\n",
        "        return sentence_vector\n",
        "    else:\n",
        "        # Если нет слов из word2vec модели в тексте, вернуть нулевой вектор\n",
        "        return np.zeros_like(word2vec_model['word'])\n",
        "\n",
        "# Применение функции к каждому тексту в train_text\n",
        "train_vectors = [vectorize_with_tfidf_and_word2vec(text, tfidf_weights[i], wv) for i, text in enumerate(train_texts)]\n",
        "\n",
        "# Применение функции к каждому тексту в test_texts\n",
        "test_vectors = [vectorize_with_tfidf_and_word2vec(text, tfidf_weights[i], wv) for i, text in enumerate(test_texts)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import алгоритма из библиотеки\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# инициализируем модель\n",
        "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
        "\n",
        "# обучаем ее на тренировочных данных\n",
        "clf = clf.fit(train_vectors, train_y)\n",
        "\n",
        "# делаем предсказание для тестовых данных\n",
        "pred = clf.predict(test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy: ', accuracy_score(test_y, pred))\n",
        "print('F1: ', f1_score(test_y, pred, average = 'macro'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
